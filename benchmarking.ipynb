{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463ee857",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4aa311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mirdata\n",
    "from pesto import load_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import mir_eval\n",
    "import pesto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898df4ef",
   "metadata": {},
   "source": [
    "# Benchmarking on MDB-stem-synth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8a4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Downloading ['mdb_stem_synth', 'index']. Index is being stored in C:\\Users\\titou\\Desktop\\python_test_files\\virtual_environments\\python_3.12\\series_temp\\Lib\\site-packages\\mirdata\\datasets\\indexes, and the rest of files in /tmp\\mir_datasets\\mdb_stem_synth\n",
      "WARNING: [mdb_stem_synth] downloading MDB-stem-synth.tar.gz\n",
      "1.72GB [10:02, 3.06MB/s]                               \n",
      "WARNING: [index] downloading mdb_stem_synth_index_1.0.0.json\n",
      "72.0kB [00:00, 160kB/s]                             \n"
     ]
    }
   ],
   "source": [
    "dataset = mirdata.initialize(\"mdb_stem_synth\")\n",
    "#dataset.download() this line has to be commented and re-run if the dataset is not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cde33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import mir_eval\n",
    "import pesto\n",
    "from pesto import load_model\n",
    "\n",
    "# ---- dataset / track ----\n",
    "track_id = \"AClassicEducation_NightOwl_STEM_01\"\n",
    "track = dataset.track(track_id)  # assumes `dataset` already exists\n",
    "audio, sr = track.audio  # mirdata returns (samples, channels) usually\n",
    "\n",
    "# ---- mono + torch tensor (PESTO guideline) ----\n",
    "audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "x = torch.from_numpy(audio_mono).float()  # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4a81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- mono + torch tensor (PESTO guideline) ----\n",
    "audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "x = torch.from_numpy(audio_mono).float()  # (num_samples,)\n",
    "\n",
    "# ---- device + model (load once) ----\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "\n",
    "# Important: pass sampling_rate to match your data (repo shows this pattern in advanced usage)\n",
    "pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr).to(device)\n",
    "pesto_model.eval()\n",
    "\n",
    "# ---- inference ----\n",
    "with torch.no_grad():\n",
    "    # Repo example uses: f0, conf, amp = f0_estimator(x, convert_to_freq=True, return_activations=False)\n",
    "    f0, conf, amp = pesto_model(\n",
    "        x.to(device),\n",
    "        convert_to_freq=True,\n",
    "        return_activations=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ace1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for Track: AClassicEducation_NightOwl_STEM_01 ---\n",
      "Raw Pitch Accuracy (RPA): 0.8691\n",
      "Raw Chroma Accuracy (RCA): 0.9100\n"
     ]
    }
   ],
   "source": [
    "# ---- move to numpy and build timestamps (repo: step_size in ms; hop is derived from it) ----\n",
    "f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "\n",
    "# mir_eval expects unvoiced = 0 Hz (not NaN)\n",
    "f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "\n",
    "# ---- reference ----\n",
    "ref_times = track.f0.times\n",
    "ref_freqs = track.f0.frequencies\n",
    "\n",
    "# ---- metrics ----\n",
    "scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "print(f\"--- Results for Track: {track_id} ---\")\n",
    "print(f\"Raw Pitch Accuracy (RPA): {scores['Raw Pitch Accuracy']:.4f}\")\n",
    "print(f\"Raw Chroma Accuracy (RCA): {scores['Raw Chroma Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc0a64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.track_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_312_series_temp",
   "language": "python",
   "name": "series_temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
