{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463ee857",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4aa311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mirdata\n",
    "from pesto import load_model\n",
    "import torch\n",
    "import mir_eval\n",
    "import pesto\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e2b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for WSL / crepe\n",
    "import mirdata\n",
    "import mir_eval\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import crepe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898df4ef",
   "metadata": {},
   "source": [
    "# Benchmarking on MDB-stem-synth with PESTO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa8a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mirdata.initialize(\"mdb_stem_synth\")\n",
    "# dataset.download() #this line has to be commented and re-run if the dataset is not already installed\n",
    "# dataset.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816e476",
   "metadata": {},
   "source": [
    "### Single track (test) benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cde33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- dataset / track ----\n",
    "track_id = \"AClassicEducation_NightOwl_STEM_01\"\n",
    "track = dataset.track(track_id)  # assumes `dataset` already exists\n",
    "audio, sr = track.audio  # mirdata returns (samples, channels) usually\n",
    "\n",
    "# ---- mono + torch tensor (PESTO guideline) ----\n",
    "audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "x = torch.from_numpy(audio_mono).float()  # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- device + model (load once) ----\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "\n",
    "# Important: pass sampling_rate to match your data (repo shows this pattern in advanced usage)\n",
    "pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr).to(device)\n",
    "pesto_model.eval()\n",
    "\n",
    "# ---- inference ----\n",
    "with torch.no_grad():\n",
    "    # Repo example uses: f0, conf, amp = f0_estimator(x, convert_to_freq=True, return_activations=False)\n",
    "    f0, conf, amp = pesto_model(\n",
    "        x.to(device),\n",
    "        convert_to_freq=True,\n",
    "        return_activations=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ace1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Results for Track: AClassicEducation_NightOwl_STEM_01 ---\n",
      "Raw Pitch Accuracy (RPA): 0.8691\n",
      "Raw Chroma Accuracy (RCA): 0.9100\n"
     ]
    }
   ],
   "source": [
    "# ---- move to numpy and build timestamps (repo: step_size in ms; hop is derived from it) ----\n",
    "f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "\n",
    "# mir_eval expects unvoiced = 0 Hz (not NaN)\n",
    "f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "\n",
    "# ---- reference ----\n",
    "ref_times = track.f0.times\n",
    "ref_freqs = track.f0.frequencies\n",
    "\n",
    "# ---- metrics ----\n",
    "scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "print(f\"--- Results for Track: {track_id} ---\")\n",
    "print(f\"Raw Pitch Accuracy (RPA): {scores['Raw Pitch Accuracy']:.4f}\")\n",
    "print(f\"Raw Chroma Accuracy (RCA): {scores['Raw Chroma Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6415898",
   "metadata": {},
   "source": [
    "### Full dataset bechmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26820674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tracks: 100%|██████████| 230/230 [17:18<00:00,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on MDB with PESTO:  {'Overall Accuracy': np.float64(0.39504905628006476), 'Raw Pitch Accuracy': np.float64(0.9098419948224401), 'Raw Chroma Accuracy': np.float64(0.9358192913900837), 'Voicing Recall': np.float64(0.9999996735270973), 'Voicing False Alarm': np.float64(0.9998373050855409)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "\n",
    "metrics = [\n",
    "    \"Overall Accuracy\",\n",
    "    \"Raw Pitch Accuracy\",\n",
    "    \"Raw Chroma Accuracy\",\n",
    "    \"Voicing Recall\",\n",
    "    \"Voicing False Alarm\",\n",
    "]\n",
    "\n",
    "# load once (reload only if sr changes)\n",
    "track0 = dataset.track(dataset.track_ids[0])\n",
    "audio0, sr0 = track0.audio\n",
    "\n",
    "pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device).eval()\n",
    "\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for track_id in tqdm(dataset.track_ids, desc=\"Evaluating tracks\"):\n",
    "        track = dataset.track(track_id)\n",
    "\n",
    "        audio, sr = track.audio\n",
    "        if sr != sr0:\n",
    "            sr0 = sr\n",
    "            pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device).eval()\n",
    "\n",
    "        audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "        x = torch.from_numpy(audio_mono).float().to(device)\n",
    "\n",
    "        f0, conf, amp = pesto_model(x, convert_to_freq=True, return_activations=False)\n",
    "\n",
    "        f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "        f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "        times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "\n",
    "        ref_times = track.f0.times\n",
    "        ref_freqs = track.f0.frequencies\n",
    "\n",
    "        scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "        w = float(ref_times.shape[0])\n",
    "        sum_w += w\n",
    "        for m in metrics:\n",
    "            sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(\"Scores on MDB with PESTO: \",final_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679fd58",
   "metadata": {},
   "source": [
    "# Benchmarking on Orchset with PESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.39it/s]\n",
      "100%|██████████| 64/64 [00:02<00:00, 31.10it/s]\n",
      "WARNING: Success: the dataset is complete and all files are valid.\n",
      "WARNING: --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'metadata': {}, 'tracks': {}}, {'metadata': {}, 'tracks': {}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = mirdata.initialize(\"orchset\")\n",
    "#dataset.download()\n",
    "#dataset.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9233509",
   "metadata": {},
   "source": [
    "### Single track (test) benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- orchset / Beethoven-S3-I-ex1 ---\n",
      "RPA: 0.0368\n",
      "RCA: 0.6468\n"
     ]
    }
   ],
   "source": [
    "# orchset\n",
    "track_id = dataset.track_ids[0]\n",
    "track = dataset.track(track_id)\n",
    "\n",
    "# --- audio (orchset-specific) ---\n",
    "audio, sr = track.audio_mono  # <-- correct for Orchset :contentReference[oaicite:1]{index=1}\n",
    "x = torch.from_numpy(audio).float()\n",
    "\n",
    "# --- pesto ---\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr).to(device).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    f0, conf, amp = model(x.to(device), convert_to_freq=True, return_activations=False)\n",
    "\n",
    "f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "\n",
    "# --- reference (orchset-specific) ---\n",
    "ref_times = track.melody.times\n",
    "ref_freqs = track.melody.frequencies\n",
    "\n",
    "scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "print(f\"--- orchset / {track_id} ---\")\n",
    "print(f\"RPA: {scores['Raw Pitch Accuracy']:.4f}\")\n",
    "print(f\"RCA: {scores['Raw Chroma Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae3161",
   "metadata": {},
   "source": [
    "### Full dataset Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded56231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall score for PESTO on orchestra:  {'Overall Accuracy': np.float64(0.17283344364498154), 'Raw Pitch Accuracy': np.float64(0.18264329344654404), 'Raw Chroma Accuracy': np.float64(0.482965021786439), 'Voicing Recall': np.float64(0.9999686196039806), 'Voicing False Alarm': np.float64(0.9999546722490121)}\n"
     ]
    }
   ],
   "source": [
    "dataset = mirdata.initialize(\"orchset\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "\n",
    "metrics = [\n",
    "    \"Overall Accuracy\",\n",
    "    \"Raw Pitch Accuracy\",\n",
    "    \"Raw Chroma Accuracy\",\n",
    "    \"Voicing Recall\",\n",
    "    \"Voicing False Alarm\",\n",
    "]\n",
    "\n",
    "# load once (orchset has a fixed sr in practice, but keep this robust)\n",
    "track0 = dataset.track(dataset.track_ids[0])\n",
    "audio0, sr0 = track0.audio_mono\n",
    "model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device).eval()\n",
    "\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for track_id in dataset.track_ids:\n",
    "        track = dataset.track(track_id)\n",
    "\n",
    "        audio, sr = track.audio_mono\n",
    "        if sr != sr0:\n",
    "            sr0 = sr\n",
    "            model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device).eval()\n",
    "\n",
    "        x = torch.from_numpy(audio).float().to(device)\n",
    "\n",
    "        f0, conf, amp = model(x, convert_to_freq=True, return_activations=False)\n",
    "        f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "        f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "        times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "\n",
    "        ref_times = track.melody.times\n",
    "        ref_freqs = track.melody.frequencies\n",
    "\n",
    "        scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "        w = float(ref_times.shape[0])  # frame-weight by GT frames\n",
    "        sum_w += w\n",
    "        for m in metrics:\n",
    "            sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(\"Overall score for PESTO on orchestra: \",final_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413af4be",
   "metadata": {},
   "source": [
    "# Benchmarking on vocadito with PESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91f82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mirdata.initialize(\"vocadito\")\n",
    "# dataset.download()  # vocadito is downloadable from Zenodo :contentReference[oaicite:4]{index=4}\n",
    "# dataset.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0e71c",
   "metadata": {},
   "source": [
    "### Single track (test) benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0545b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9884678747940692 0.9884678747940692\n"
     ]
    }
   ],
   "source": [
    "# ---- pick a track ----\n",
    "track_id = dataset.track_ids[0]\n",
    "track = dataset.track(track_id)\n",
    "\n",
    "audio, sr = track.audio\n",
    "\n",
    "# ---- mono ----\n",
    "audio_mono = audio\n",
    "\n",
    "x = torch.from_numpy(audio_mono).float()\n",
    "\n",
    "# ---- model ----\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr).to(device)\n",
    "pesto_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    f0, conf, amp = pesto_model(x.to(device), convert_to_freq=True, return_activations=False)\n",
    "\n",
    "f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "\n",
    "# ---- reference ----\n",
    "ref_times = track.f0.times\n",
    "ref_freqs = track.f0.frequencies\n",
    "\n",
    "scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "print(track_id, scores[\"Raw Pitch Accuracy\"], scores[\"Raw Chroma Accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cc5b2",
   "metadata": {},
   "source": [
    "### Full-data set benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbecf9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on Vocadito with PESTO:  {'Overall Accuracy': np.float64(0.647838502081232), 'Raw Pitch Accuracy': np.float64(0.9811545604137208), 'Raw Chroma Accuracy': np.float64(0.9848056886964734), 'Voicing Recall': np.float64(0.9999869620011912), 'Voicing False Alarm': np.float64(0.9993370197333225)}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "step_size_ms = 20.0\n",
    "\n",
    "# model loaded once\n",
    "track0 = dataset.track(dataset.track_ids[0])\n",
    "_, sr0 = track0.audio\n",
    "pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device)\n",
    "pesto_model.eval()\n",
    "\n",
    "metrics = [\n",
    "    \"Overall Accuracy\",\n",
    "    \"Raw Pitch Accuracy\",\n",
    "    \"Raw Chroma Accuracy\",\n",
    "    \"Voicing Recall\",\n",
    "    \"Voicing False Alarm\",\n",
    "]\n",
    "\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for track_id in dataset.track_ids:\n",
    "        track = dataset.track(track_id)\n",
    "        audio, sr = track.audio\n",
    "\n",
    "        # if sampling rates differ across tracks, reload model to match sr\n",
    "        if sr != sr0:\n",
    "            sr0 = sr\n",
    "            pesto_model = load_model(\"mir-1k_g7\", step_size=step_size_ms, sampling_rate=sr0).to(device)\n",
    "            pesto_model.eval()\n",
    "\n",
    "        audio_mono = audio.mean(axis=-1) if getattr(audio, \"ndim\", 1) > 1 else audio\n",
    "        x = torch.from_numpy(audio_mono).float().to(device)\n",
    "\n",
    "        f0, conf, amp = pesto_model(x, convert_to_freq=True, return_activations=False)\n",
    "        f0_pred = f0.detach().cpu().numpy().squeeze()\n",
    "        f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "\n",
    "        times_pred = np.arange(f0_pred.shape[-1]) * (step_size_ms / 1000.0)\n",
    "\n",
    "        ref_times = track.f0.times\n",
    "        ref_freqs = track.f0.frequencies\n",
    "\n",
    "        scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "        w = float(ref_times.shape[0])  # frame-weighting by number of GT frames\n",
    "        sum_w += w\n",
    "        for m in metrics:\n",
    "            sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(\"Scores on Vocadito with PESTO: \",final_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd696cf",
   "metadata": {},
   "source": [
    "# Benchmarking MDB with CREPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad7d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/c/tmp/mir_datasets/mdb_stem_synth\" \n",
    "dataset = mirdata.initialize(\"mdb_stem_synth\", data_home=data_path)\n",
    "# dataset.download()\n",
    "# dataset.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tracks:   0%|          | 0/230 [00:00<?, ?it/s]2026-01-04 01:29:42.934421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/titou/venvs/crepe-gpu/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767486585.557484   23439 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-01-04 01:29:51.705775: I external/local_xla/xla/service/service.cc:163] XLA service 0x7b470c00c0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-04 01:29:51.705815: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2026-01-04 01:29:51.719873: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-04 01:29:51.802058: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n",
      "2026-01-04 01:29:52.372162: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_218', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2026-01-04 01:29:53.487491: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:29:54.280373: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1767486594.805141   23596 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-04 01:29:57.300008: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:29:57.886983: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 79.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:29:58.622225: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Evaluating tracks:   1%|          | 2/230 [00:26<45:26, 11.96s/it]  "
     ]
    }
   ],
   "source": [
    "\n",
    "step_size_ms = 20.0\n",
    "voicing_thresh = 0.5\n",
    "\n",
    "metrics = [\"Overall Accuracy\", \"Raw Pitch Accuracy\", \"Raw Chroma Accuracy\", \"Voicing Recall\", \"Voicing False Alarm\"]\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "for track_id in tqdm(dataset.track_ids, desc=\"Evaluating tracks\"):\n",
    "    track = dataset.track(track_id)\n",
    "\n",
    "    audio, sr = track.audio\n",
    "    audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "\n",
    "    times_pred, f0_pred, conf, _ = crepe.predict(\n",
    "        audio_mono,\n",
    "        sr,\n",
    "        step_size=step_size_ms,\n",
    "        viterbi=False,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "    f0_pred = np.where(conf >= voicing_thresh, f0_pred, 0.0)\n",
    "\n",
    "    ref_times = track.f0.times\n",
    "    ref_freqs = track.f0.frequencies\n",
    "\n",
    "    scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "    w = float(ref_times.shape[0])\n",
    "    sum_w += w\n",
    "    for m in metrics:\n",
    "        sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(final_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fdc35",
   "metadata": {},
   "source": [
    "# Benchmarking Orhcest with CREPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027329d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Downloading ['all', 'index']. Index is being stored in /home/titou/venvs/crepe-gpu/lib/python3.12/site-packages/mirdata/datasets/indexes, and the rest of files in /mnt/c/tmp/mir_datasets/orchset\n",
      "WARNING: [all] downloading Orchset_dataset_0.zip\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/Orchset_dataset_0.zip already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/audio already exists. Run with force_overwrite=True to download from scratch\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/GT already exists. Run with force_overwrite=True to download from scratch\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/midi already exists. Run with force_overwrite=True to download from scratch\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/Orchset - Predominant Melodic Instruments.csv already exists. Run with force_overwrite=True to download from scratch\n",
      "WARNING: /mnt/c/tmp/mir_datasets/orchset/README.txt already exists. Run with force_overwrite=True to download from scratch\n",
      "WARNING: [index] downloading orchset_index_1.0.json\n",
      "32.0kB [00:00, 143kB/s]                             \n",
      "100%|██████████| 1/1 [00:00<00:00, 46.54it/s]\n",
      "100%|██████████| 64/64 [00:19<00:00,  3.25it/s]\n",
      "WARNING: Success: the dataset is complete and all files are valid.\n",
      "WARNING: --------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'metadata': {}, 'tracks': {}}, {'metadata': {}, 'tracks': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/mnt/c/tmp/mir_datasets/orchset\" \n",
    "dataset = mirdata.initialize(\"orchset\", data_home=data_path)\n",
    "# dataset.download()\n",
    "# dataset.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e06da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tracks: 100%|██████████| 64/64 [00:59<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on Orchestra with CREPE:  {'Overall Accuracy': np.float64(0.15466404765463201), 'Raw Pitch Accuracy': np.float64(0.13194821346421762), 'Raw Chroma Accuracy': np.float64(0.365956993830301), 'Voicing Recall': np.float64(0.5789966514288181), 'Voicing False Alarm': np.float64(0.5298053465740868)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "step_size_ms = 20.0\n",
    "voicing_thresh = 0.5\n",
    "\n",
    "metrics = [\"Overall Accuracy\", \"Raw Pitch Accuracy\", \"Raw Chroma Accuracy\", \"Voicing Recall\", \"Voicing False Alarm\"]\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "for track_id in tqdm(dataset.track_ids, desc=\"Evaluating tracks\"):\n",
    "    track = dataset.track(track_id)\n",
    "\n",
    "    audio, sr = track.audio_mono\n",
    "\n",
    "    times_pred, f0_pred, conf, _ = crepe.predict(\n",
    "        audio,\n",
    "        sr,\n",
    "        step_size=step_size_ms,\n",
    "        viterbi=False,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "    f0_pred = np.where(conf >= voicing_thresh, f0_pred, 0.0)\n",
    "\n",
    "    ref_times = track.melody.times\n",
    "    ref_freqs = track.melody.frequencies\n",
    "\n",
    "    scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "    w = float(ref_times.shape[0])\n",
    "    sum_w += w\n",
    "    for m in metrics:\n",
    "        sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(\"Scores on Orchestra with CREPE: \",final_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b9fcd",
   "metadata": {},
   "source": [
    "# Benchmarking vocadito with CREPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d16653",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mirdata.initialize(\"vocadito\")\n",
    "# dataset.download()\n",
    "# dataset.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c1d19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating tracks:   0%|          | 0/40 [00:00<?, ?it/s]2026-01-04 00:59:53.956767: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/titou/venvs/crepe-gpu/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767484796.350275   10511 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2026-01-04 00:59:58.711739: I external/local_xla/xla/service/service.cc:163] XLA service 0x77b27800bc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-04 00:59:58.711779: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2026-01-04 00:59:58.722617: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-04 00:59:58.791491: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91701\n",
      "2026-01-04 00:59:59.357142: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_218', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2026-01-04 01:00:00.125467: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 80.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:00:00.837255: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1767484801.289280   10758 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2026-01-04 01:00:02.433288: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:00:02.989474: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 79.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:00:48.478897: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=0} for conv (f32[29,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:00:03.334080: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 121.34119ms\n",
      "Trying algorithm eng12{k11=0} for conv (f32[29,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:00:03.667551: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Evaluating tracks:   2%|▎         | 1/40 [00:11<07:13, 11.11s/it]2026-01-04 01:00:05.261546: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 68.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:00:05.808507: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Evaluating tracks:   5%|▌         | 2/40 [00:13<03:39,  5.77s/it]2026-01-04 01:00:07.502907: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 69.59GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:00:08.073382: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Evaluating tracks:   8%|▊         | 3/40 [00:15<02:34,  4.17s/it]2026-01-04 01:00:09.667644: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:00:10.125804: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 75.63GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-04 01:00:10.768008: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "Evaluating tracks:  10%|█         | 4/40 [00:17<02:07,  3.53s/it]2026-01-04 01:00:12.416698: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:00:58.493667: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=1,k13=1,k14=0,k22=1} for conv (f32[31,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:00:58.496112: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 45.259525513s\n",
      "Trying algorithm eng33{k2=2,k6=1,k13=1,k14=0,k22=1} for conv (f32[31,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks:  15%|█▌        | 6/40 [00:23<01:39,  2.92s/it]2026-01-04 01:00:17.471210: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:01:03.511066: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=0} for conv (f32[23,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:01:03.511782: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 45.371006943s\n",
      "Trying algorithm eng12{k11=0} for conv (f32[23,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[23,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks:  20%|██        | 8/40 [00:26<01:10,  2.20s/it]2026-01-04 01:00:21.195805: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "Evaluating tracks:  22%|██▎       | 9/40 [00:29<01:16,  2.46s/it]2026-01-04 01:00:24.479819: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "Evaluating tracks:  25%|██▌       | 10/40 [00:32<01:20,  2.67s/it]2026-01-04 01:00:27.547191: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:01:13.522314: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng13{} for conv (f32[21,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:01:13.523895: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 45.259614593s\n",
      "Trying algorithm eng13{} for conv (f32[21,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[21,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks:  30%|███       | 12/40 [00:38<01:15,  2.68s/it]2026-01-04 01:00:32.378391: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:01:18.524541: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=0} for conv (f32[20,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:00:33.408837: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 208.288752ms\n",
      "Trying algorithm eng12{k11=0} for conv (f32[20,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks:  60%|██████    | 24/40 [00:57<00:28,  1.76s/it]2026-01-04 01:00:52.138253: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2026-01-04 01:01:38.556551: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=0} for conv (f32[30,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:00:53.345899: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 222.731338ms\n",
      "Trying algorithm eng12{k11=0} for conv (f32[30,256,16,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[30,128,79,1]{3,2,1,0}, f32[256,128,64,1]{3,2,1,0}, f32[256]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks:  70%|███████   | 28/40 [01:05<00:19,  1.63s/it]2026-01-04 01:01:00.042284: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_237', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "Evaluating tracks:  72%|███████▎  | 29/40 [01:08<00:22,  2.03s/it]2026-01-04 01:01:48.563593: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=0} for conv (f32[12,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2026-01-04 01:01:03.359222: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took -311.035005ms\n",
      "Trying algorithm eng12{k11=0} for conv (f32[12,128,32,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[12,128,95,1]{3,2,1,0}, f32[128,128,64,1]{3,2,1,0}, f32[128]{0}), window={size=64x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "Evaluating tracks: 100%|██████████| 40/40 [01:23<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final scores on vocadito with CREPE:  {'Overall Accuracy': np.float64(0.891207682800358), 'Raw Pitch Accuracy': np.float64(0.9686287550960121), 'Raw Chroma Accuracy': np.float64(0.9718860625183027), 'Voicing Recall': np.float64(0.98306390568432), 'Voicing False Alarm': np.float64(0.2670181517978474)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "step_size_ms = 20.0\n",
    "voicing_thresh = 0.5  # common default; tune if you want\n",
    "\n",
    "metrics = [\"Overall Accuracy\", \"Raw Pitch Accuracy\", \"Raw Chroma Accuracy\", \"Voicing Recall\", \"Voicing False Alarm\"]\n",
    "sum_w = 0.0\n",
    "sum_scores = {m: 0.0 for m in metrics}\n",
    "\n",
    "for track_id in tqdm(dataset.track_ids, desc=\"Evaluating tracks\"):\n",
    "    track = dataset.track(track_id)\n",
    "\n",
    "    audio, sr = track.audio\n",
    "    audio_mono = audio.mean(axis=-1) if audio.ndim > 1 else audio\n",
    "\n",
    "    times_pred, f0_pred, conf, _ = crepe.predict(\n",
    "        audio_mono,\n",
    "        sr,\n",
    "        step_size=step_size_ms,\n",
    "        viterbi=False,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    f0_pred = np.nan_to_num(f0_pred, nan=0.0)\n",
    "    f0_pred = np.where(conf >= voicing_thresh, f0_pred, 0.0)\n",
    "\n",
    "    ref_times = track.f0.times\n",
    "    ref_freqs = track.f0.frequencies\n",
    "\n",
    "    scores = mir_eval.melody.evaluate(ref_times, ref_freqs, times_pred, f0_pred)\n",
    "\n",
    "    w = float(ref_times.shape[0])\n",
    "    sum_w += w\n",
    "    for m in metrics:\n",
    "        sum_scores[m] += scores[m] * w\n",
    "\n",
    "final_scores = {m: (sum_scores[m] / sum_w) for m in metrics}\n",
    "print(\"Final scores on vocadito with CREPE: \", final_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crepe-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
